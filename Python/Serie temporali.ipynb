{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DA PROVARE\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def get_train_and_test_from_timeseries(dataframe, train_size, outputs_col, verbose=0):\n",
    "    '''\n",
    "        Splits a dataset of a time series in its corrispective train and test parts.\n",
    "        It keeps the order of the dataset.\n",
    "        \n",
    "        Attributes:\n",
    "            - dataframe      (pandas.DataFrame) : \n",
    "            - train_size     (int)              : the percentage of the dataframe to keep in the training set (0 < train_size <= 1)\n",
    "            - outputs        ([string])         : the outputs columns\n",
    "            - verbose        (int)\n",
    "\n",
    "        Returns:\n",
    "            - (pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame): train_X, train_Y, test_X, test_Y\n",
    "    '''\n",
    "\n",
    "    assert type(dataframe) == pd.DataFrame\n",
    "    assert train_size > 0 and train_size <= 1, 'The percentage of the train_size need to be greather than 0 and less or equal to 1.'\n",
    "    assert outputs_col is not None and len(outputs_col) > 0\n",
    "\n",
    "    nrow = round(train_size * dataframe.shape[0])\n",
    "\n",
    "    train = series.iloc[:nrow, :]\n",
    "    test = series.iloc[nrow:, :]\n",
    "\n",
    "    train_X = train.drop(columns=output)\n",
    "    test_X = test.drop(columns=output)\n",
    "\n",
    "    train_Y = train[output]\n",
    "    test_Y = test[output]\n",
    "\n",
    "    if verbose == 1:\n",
    "        print('Training set shape for X (inputs):')\n",
    "        print(train_X.shape)\n",
    "        print('Training set shape for Y (output):')\n",
    "        print(train_Y.shape)\n",
    "        print('Test set shape for X (inputs):')\n",
    "        print(test_X.shape)\n",
    "        print('Test set shape for Y (output):')\n",
    "        print(test_Y.shape)\n",
    "    \n",
    "    return train_X, train_Y, test_X, test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DA PROVARE\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def create_window_multivariate(data, window_size_backward=1, window_size_forward=None, full_forward=True):    \n",
    "    '''\n",
    "        Starting from a pandas.DataFrame it create a windowed version, \n",
    "         with values from the past and from the future. \n",
    "        \n",
    "        Attributes:\n",
    "            - data                  : (pandas.DataFrame)   original dataframe\n",
    "            - window_size_backward  : (int)                window size (in the past)\n",
    "            - window_size_forward   : (int, default None)  window size (in the future). If None, only past values are going to be aggregated\n",
    "            - full_forward          : (bool, default True) when window_size_forward != 0 indicates if all the values, from the actual to the window_size_forwardth must been kept\n",
    "            \n",
    "        Return:\n",
    "            - pandas.DataFrame      : the windowed version of the original dataframe:\n",
    "                                        - the columns in the past have the same name of the originals followed by a -1\n",
    "                                        - the columns in the future have the same name of the originals followed by a +1\n",
    "    '''\n",
    "    \n",
    "    # it has to be greater than 0\n",
    "    assert type(window_size_backward) == int and window_size_backward > 0\n",
    "    \n",
    "    res = []\n",
    "    for c in data.columns:\n",
    "\n",
    "        sub_df = data[[c]].copy()\n",
    "        data_s = sub_df.copy()\n",
    "        col_name = [c]\n",
    "        for i in range(window_size_backward):\n",
    "            col_name.append(c + '-' + str(i))\n",
    "            sub_df = pd.concat([sub_df, data_s.shift((i + 1))], axis = 1)\n",
    "        \n",
    "        # if not none it has to be greater than 0\n",
    "        if window_size_forward is not None and type(window_size_forward == int) and window_size_forward > 0:\n",
    "            column_to_delete = []\n",
    "            for i in range(1, window_size_forward + 1):\n",
    "                \n",
    "                if full_forward == False:\n",
    "                    if i != window_size_forward:\n",
    "                        column_to_delete.append(c + '+' + str(i))\n",
    "                \n",
    "                col_name.append(c + '+' + str(i))\n",
    "                sub_df = pd.concat([sub_df, data_s.shift((-i))], axis = 1)\n",
    "            \n",
    "        sub_df.dropna(axis=0, inplace=True)\n",
    "        sub_df.columns = col_name\n",
    "        \n",
    "        if full_forward == False and len(column_to_delete) > 0:\n",
    "            sub_df.drop(columns=column_to_delete, inplace=True)\n",
    "\n",
    "\n",
    "        res.append(sub_df)\n",
    "\n",
    "    final_df = pd.concat(res, axis=1)\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previsioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DA PROVARE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_prediction_train_vs_test(window_size, df, feature, train_predict, test_predict):  \n",
    "    '''\n",
    "        Plots the results of the predictions (on train and on test) of a model (UNIVARIATE) for time series.\n",
    "        Assuming that the source data comes from a Pandas dataframe.\n",
    "\n",
    "        Attributes:\n",
    "            - window_size: (int) dimension of the window used for prediction\n",
    "            - df: (Pandas.DataFrame) original dataframe\n",
    "            - feature: (string) column of the dataframe on which the model has been trained\n",
    "            - train_predict: (array[float]) predictions on train set\n",
    "            - test_predict: (array[float]) predictions on test set\n",
    "    '''\n",
    "\n",
    "    # Start with training predictions\n",
    "    train_predict_plot = np.empty_like(df.filter([feature]))\n",
    "    train_predict_plot[:, :] = np.nan\n",
    "    train_predict_plot[window_size:window_size + len(train_predict), :] = train_predict\n",
    "\n",
    "    # Add test predictions\n",
    "    test_predict_plot = np.empty_like(df.filter([feature]))\n",
    "    test_predict_plot[:, :] = np.nan\n",
    "    test_predict_plot[window_size + len(train_predict):df.shape[0], :] = test_predict\n",
    "\n",
    "    # Create the plot\n",
    "    plt.plot(df[feature].values, label = 'True value', alpha=0.4)\n",
    "    plt.plot(train_predict_plot, label = 'Training set prediction')\n",
    "    plt.plot(test_predict_plot, label = 'Test set prediction')\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('Values')\n",
    "    plt.title('Comparison true vs. predicted training / test')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decomposizione stagionale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DA PROVARE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "def plot_seasonal_decomposition(dataframe, feature, figsize=(30, 10)):\n",
    "    '''\n",
    "        Plots the seasonal decomposition of a time series\n",
    "\n",
    "        Attributes:\n",
    "            - dataframe: (pandas.DataFrame)\n",
    "            - feature: (string) the column of the DF on which to perform decomposition\n",
    "            - figsize: ((X_dim, Y_dim)) the dimension of the figure\n",
    "\n",
    "    '''\n",
    "\n",
    "    decompositions = seasonal_decompose(dataframe[feature], model='additive')\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(decompositions.trend, label='trend')\n",
    "    plt.plot(decompositions.seasonal, label='seasonal')\n",
    "    plt.plot(decompositions.resid, label='residual')\n",
    "    plt.plot(decompositions.observed, label='observed')\n",
    "    plt.title('Seasonal decomposition for: ' + str(feature))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## White Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DA PROVARE\n",
    "\n",
    "from pandas.tools.plotting import autocorrelation_plot\n",
    "\n",
    "def check_series_is_white_noise(df, feature):\n",
    "    '''\n",
    "    '''\n",
    "    autocorrelation_plot(df[feature].fillna(0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocorrelazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DA PROVARE\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def autocorr(x):\n",
    "    '''\n",
    "        Autocorrelation check\n",
    "\n",
    "        Attributes:\n",
    "            - x (numpy.array) : input array \n",
    "\n",
    "        Returns:\n",
    "            - float : r\n",
    "            - float : lag\n",
    "    '''\n",
    "    n = x.size\n",
    "    norm = (x - np.mean(x))\n",
    "    result = np.correlate(norm, norm, mode='same')\n",
    "    acorr = result[n//2 + 1:] / (x.var() * np.arange(n-1, n//2, -1))\n",
    "    lag = np.abs(acorr).argmax() + 1\n",
    "    r = acorr[lag-1]        \n",
    "    if np.abs(r) > 0.5:\n",
    "      print('Appears to be autocorrelated with r = {}, lag = {}'. format(r, lag))\n",
    "    else: \n",
    "      print('Appears to be not autocorrelated')\n",
    "    return r, lag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DA PROVARE \n",
    "\n",
    "def remove_correlated_columns(dataframe, threshold=0.95):\n",
    "    '''\n",
    "        Removes the columns of a dataframe that are correlated more that threshold\n",
    "\n",
    "        Attrubutes:\n",
    "            - dataframe: (pandas.DataFrame) the original dataframe\n",
    "            - threshold: (float, default = 0.95) the lower threshold for the correlation\n",
    "\n",
    "        Returns:\n",
    "            - pandas.DataFrame : a copy of the original dataframe without the correlated columns\n",
    "            - [string] : the columns dropped\n",
    "    '''\n",
    "    df = dataframe.copy()\n",
    "\n",
    "    # Create correlation matrix\n",
    "    corr_matrix = df.corr().abs()\n",
    "\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "    # Find index of feature columns with correlation greater than threshold\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "\n",
    "    # Drop features \n",
    "    df.drop(df.columns[to_drop], axis=1, inplace=True)\n",
    "\n",
    "    return df, to_drop"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
