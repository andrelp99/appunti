{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\andre\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\andre\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from beautifulsoup4) (2.4.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping GitHub Profile using Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\andre\\OneDrive\\Documenti\\tuttooo\\Python\\Web Scraping.ipynb Cell 3\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andre/OneDrive/Documenti/tuttooo/Python/Web%20Scraping.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m req \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(github_profile)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andre/OneDrive/Documenti/tuttooo/Python/Web%20Scraping.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m scraper \u001b[39m=\u001b[39m bs(req\u001b[39m.\u001b[39mcontent, \u001b[39m\"\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/andre/OneDrive/Documenti/tuttooo/Python/Web%20Scraping.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m profile_picture \u001b[39m=\u001b[39m scraper\u001b[39m.\u001b[39;49mfind(\u001b[39m\"\u001b[39;49m\u001b[39mimg\u001b[39;49m\u001b[39m\"\u001b[39;49m, {\u001b[39m\"\u001b[39;49m\u001b[39malt\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mAvatar\u001b[39;49m\u001b[39m\"\u001b[39;49m})[\u001b[39m\"\u001b[39;49m\u001b[39msrc\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andre/OneDrive/Documenti/tuttooo/Python/Web%20Scraping.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(profile_picture)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "github_profile = \"https://github.com/amankharwal\"\n",
    "req = requests.get(github_profile)\n",
    "scraper = bs(req.content, \"html.parser\")\n",
    "profile_picture = scraper.find(\"img\", {\"alt\": \"Avatar\"})[\"src\"]\n",
    "print(profile_picture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Table from a Website using Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Websites Popularity (unique visitors per month)[1]  \\\n",
      "0  Google[2]                                2800000000   \n",
      "1   Facebook                                1120000000   \n",
      "2    YouTube                                1100000000   \n",
      "3      Yahoo                                 750000000   \n",
      "4       Etsy       516,000,000 (Total, not unique)[14]   \n",
      "\n",
      "        Front-end (Client-side)  \\\n",
      "0        JavaScript, TypeScript   \n",
      "1  JavaScript, Typescript, Flow   \n",
      "2        JavaScript, TypeScript   \n",
      "3                    JavaScript   \n",
      "4                    JavaScript   \n",
      "\n",
      "                              Back-end (Server-side)  \\\n",
      "0                  C, C++, Go,[3] Java, Python, Node   \n",
      "1  Hack/HHVM, Python, C++, Java, Erlang, D,[6] Ha...   \n",
      "2                   Python, C, C++, Java,[10] Go[11]   \n",
      "3                                                PHP   \n",
      "4                                        PHP[15][16]   \n",
      "\n",
      "                                     Database  \\\n",
      "0                     Bigtable,[4] MariaDB[5]   \n",
      "1      MariaDB, MySQL,[8] HBase, Cassandra[9]   \n",
      "2            Vitess, BigTable, MariaDB[5][12]   \n",
      "3  PostgreSQL, HBase, Cassandra, MongoDB,[13]   \n",
      "4                            MySQL, Redis[17]   \n",
      "\n",
      "                                       Notes  \n",
      "0  The most used search engine in the world.  \n",
      "1   The most visited social networking site.  \n",
      "2       The most popular video sharing site.  \n",
      "3                                        NaN  \n",
      "4                        E-commerce website.  \n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import pandas as pd\n",
    "url = \"https://en.wikipedia.org/wiki/Programming_languages_used_in_most_popular_websites\"\n",
    "\n",
    "with urllib.request.urlopen(url) as i:\n",
    "    html = i.read()\n",
    "    \n",
    "data = pd.read_html(html)[0]\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_csv(\"programming.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping to Create a Dataset using Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xad in position 3322: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\andre\\OneDrive\\Documenti\\tuttooo\\Python\\Web Scraping.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/andre/OneDrive/Documenti/tuttooo/Python/Web%20Scraping.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         writer\u001b[39m.\u001b[39mwriterow(row)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/andre/OneDrive/Documenti/tuttooo/Python/Web%20Scraping.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/andre/OneDrive/Documenti/tuttooo/Python/Web%20Scraping.ipynb#X10sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m a \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39mlanguage.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/andre/OneDrive/Documenti/tuttooo/Python/Web%20Scraping.ipynb#X10sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m a\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1753\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1750\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1752\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1753\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping[engine](f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions)\n\u001b[0;32m   1754\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1755\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:79\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     76\u001b[0m     kwds\u001b[39m.\u001b[39mpop(key, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m     78\u001b[0m kwds[\u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m ensure_dtype_objs(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m---> 79\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader \u001b[39m=\u001b[39m parsers\u001b[39m.\u001b[39mTextReader(src, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     81\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munnamed_cols \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39munnamed_cols\n\u001b[0;32m     83\u001b[0m \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:547\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:636\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1965\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xad in position 3322: invalid start byte"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen(\"https://en.wikipedia.org/wiki/Comparison_of_programming_languages\")\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "table = soup.findAll(\"table\", {\"class\":\"wikitable\"})[0]\n",
    "rows = table.findAll(\"tr\")\n",
    "\n",
    "with open(\"language.csv\", \"wt+\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    for i in rows:\n",
    "        row = []\n",
    "        for cell in i.findAll([\"td\", \"th\"]):\n",
    "            row.append(cell.get_text())\n",
    "        writer.writerow(row)\n",
    "   \n",
    "  \n",
    "import pandas as pd\n",
    "a = pd.read_csv(\"language.csv\")\n",
    "a.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Twitter with Python (no API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting twint\n",
      "  Downloading twint-2.1.20.tar.gz (31 kB)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.6-cp39-cp39-win_amd64.whl (329 kB)\n",
      "Collecting aiodns\n",
      "  Downloading aiodns-3.1.1-py3-none-any.whl (5.4 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\andre\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from twint) (4.12.2)\n",
      "Collecting cchardet\n",
      "  Downloading cchardet-2.1.7-cp39-cp39-win_amd64.whl (115 kB)\n",
      "Collecting elasticsearch\n",
      "  Downloading elasticsearch-8.10.1-py3-none-any.whl (409 kB)\n",
      "Requirement already satisfied: pysocks in c:\\users\\andre\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from twint) (1.7.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\andre\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from twint) (1.5.3)\n",
      "Collecting aiohttp_socks\n",
      "  Downloading aiohttp_socks-0.8.4-py3-none-any.whl (9.6 kB)\n",
      "Collecting schedule\n",
      "  Downloading schedule-1.2.1-py2.py3-none-any.whl (11 kB)\n",
      "Collecting geopy\n",
      "  Downloading geopy-2.4.0-py3-none-any.whl (125 kB)\n",
      "Collecting fake-useragent\n",
      "  Downloading fake_useragent-1.3.0-py3-none-any.whl (15 kB)\n",
      "Collecting googletransx\n",
      "  Downloading googletransx-2.4.2.tar.gz (13 kB)\n",
      "Collecting pycares>=4.0.0\n",
      "  Downloading pycares-4.4.0-cp39-cp39-win_amd64.whl (76 kB)\n",
      "Requirement already satisfied: cffi>=1.5.0 in c:\\users\\andre\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pycares>=4.0.0->aiodns->twint) (1.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\andre\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from cffi>=1.5.0->pycares>=4.0.0->aiodns->twint) (2.21)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp39-cp39-win_amd64.whl (28 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.4.0-cp39-cp39-win_amd64.whl (44 kB)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\andre\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->twint) (3.1.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\andre\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->twint) (23.1.0)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.2-cp39-cp39-win_amd64.whl (61 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\andre\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp->twint) (3.4)\n",
      "Collecting python-socks[asyncio]<3.0.0,>=2.4.3\n",
      "  Downloading python_socks-2.4.3-py3-none-any.whl (52 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\andre\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from beautifulsoup4->twint) (2.4.1)\n",
      "Collecting elastic-transport<9,>=8\n",
      "  Downloading elastic_transport-8.4.1-py3-none-any.whl (59 kB)\n",
      "Requirement already satisfied: urllib3<2,>=1.26.2 in c:\\users\\andre\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from elastic-transport<9,>=8->elasticsearch->twint) (1.26.15)\n",
      "Requirement already satisfied: certifi in c:\\users\\andre\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from elastic-transport<9,>=8->elasticsearch->twint) (2022.12.7)\n",
      "Requirement already satisfied: importlib-resources>=5.0 in c:\\users\\andre\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from fake-useragent->twint) (5.12.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\andre\\appdata\\roaming\\python\\python39\\site-packages (from importlib-resources>=5.0->fake-useragent->twint) (3.15.0)\n",
      "Collecting geographiclib<3,>=1.52\n",
      "  Downloading geographiclib-2.0-py3-none-any.whl (40 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\andre\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from googletransx->twint) (2.28.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\andre\\appdata\\roaming\\python\\python39\\site-packages (from pandas->twint) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\andre\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->twint) (1.24.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\andre\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->twint) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\andre\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->twint) (1.16.0)\n",
      "Building wheels for collected packages: twint, googletransx\n",
      "  Building wheel for twint (setup.py): started\n",
      "  Building wheel for twint (setup.py): finished with status 'done'\n",
      "  Created wheel for twint: filename=twint-2.1.20-py3-none-any.whl size=33954 sha256=4464b0c829b5ad107359a02827b6fe9bcc55d8fe3f40389423cd7e3a3f2e8374\n",
      "  Stored in directory: c:\\users\\andre\\appdata\\local\\pip\\cache\\wheels\\12\\2c\\16\\fded468865c08c82d4e82535f33c50462a3e6e042d8f93df13\n",
      "  Building wheel for googletransx (setup.py): started\n",
      "  Building wheel for googletransx (setup.py): finished with status 'done'\n",
      "  Created wheel for googletransx: filename=googletransx-2.4.2-py3-none-any.whl size=16023 sha256=d19924fd5a9a4bc4479aafe6ddf184172fa14089e170b2e38fafbda44d19aa02\n",
      "  Stored in directory: c:\\users\\andre\\appdata\\local\\pip\\cache\\wheels\\b5\\28\\37\\a905af06d6f6c934042babb4748f01b2f9039d2d96f05a4496\n",
      "Successfully built twint googletransx\n",
      "Installing collected packages: multidict, frozenlist, yarl, python-socks, async-timeout, aiosignal, pycares, geographiclib, elastic-transport, aiohttp, schedule, googletransx, geopy, fake-useragent, elasticsearch, cchardet, aiohttp-socks, aiodns, twint\n",
      "Successfully installed aiodns-3.1.1 aiohttp-3.8.6 aiohttp-socks-0.8.4 aiosignal-1.3.1 async-timeout-4.0.3 cchardet-2.1.7 elastic-transport-8.4.1 elasticsearch-8.10.1 fake-useragent-1.3.0 frozenlist-1.4.0 geographiclib-2.0 geopy-2.4.0 googletransx-2.4.2 multidict-6.0.4 pycares-4.4.0 python-socks-2.4.3 schedule-1.2.1 twint-2.1.20 yarl-1.9.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script twint.exe is installed in 'c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 21.1.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install twint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twint\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = [\n",
    "    'shakira',\n",
    "    'KimKardashian',\n",
    "    'rihanna',\n",
    "    'jtimberlake',\n",
    "    'KingJames',\n",
    "    'neymarjr',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_followings(username):\n",
    "\n",
    "    c = twint.Config()\n",
    "    c.Username = username\n",
    "    c.Pandas = True\n",
    "\n",
    "    twint.run.Following(c)\n",
    "    list_of_followings = twint.storage.panda.Follow_df\n",
    "\n",
    "    return list_of_followings['following'][username]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####\n",
      "Starting: shakira\n",
      "#####\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "This event loop is already running",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\andre\\OneDrive\\Documenti\\tuttooo\\Python\\Web Scraping.ipynb Cell 14\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andre/OneDrive/Documenti/tuttooo/Python/Web%20Scraping.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m#####\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mStarting: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m person \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m#####\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andre/OneDrive/Documenti/tuttooo/Python/Web%20Scraping.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/andre/OneDrive/Documenti/tuttooo/Python/Web%20Scraping.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     followings[person] \u001b[39m=\u001b[39m get_followings(person)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andre/OneDrive/Documenti/tuttooo/Python/Web%20Scraping.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     following_list \u001b[39m=\u001b[39m following_list \u001b[39m+\u001b[39m followings[person]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andre/OneDrive/Documenti/tuttooo/Python/Web%20Scraping.ipynb#X20sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "\u001b[1;32mc:\\Users\\andre\\OneDrive\\Documenti\\tuttooo\\Python\\Web Scraping.ipynb Cell 14\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andre/OneDrive/Documenti/tuttooo/Python/Web%20Scraping.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m c\u001b[39m.\u001b[39mUsername \u001b[39m=\u001b[39m username\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andre/OneDrive/Documenti/tuttooo/Python/Web%20Scraping.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m c\u001b[39m.\u001b[39mPandas \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/andre/OneDrive/Documenti/tuttooo/Python/Web%20Scraping.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m twint\u001b[39m.\u001b[39;49mrun\u001b[39m.\u001b[39;49mFollowing(c)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andre/OneDrive/Documenti/tuttooo/Python/Web%20Scraping.ipynb#X20sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m list_of_followings \u001b[39m=\u001b[39m twint\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39mpanda\u001b[39m.\u001b[39mFollow_df\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/andre/OneDrive/Documenti/tuttooo/Python/Web%20Scraping.ipynb#X20sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mreturn\u001b[39;00m list_of_followings[\u001b[39m'\u001b[39m\u001b[39mfollowing\u001b[39m\u001b[39m'\u001b[39m][username]\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\twint\\run.py:265\u001b[0m, in \u001b[0;36mFollowing\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m    263\u001b[0m config\u001b[39m.\u001b[39mFavorites \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    264\u001b[0m config\u001b[39m.\u001b[39mTwitterSearch \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m run(config)\n\u001b[0;32m    266\u001b[0m \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mPandas_au:\n\u001b[0;32m    267\u001b[0m     storage\u001b[39m.\u001b[39mpanda\u001b[39m.\u001b[39m_autoget(\u001b[39m\"\u001b[39m\u001b[39mfollowing\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\twint\\run.py:226\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(config, callback)\u001b[0m\n\u001b[0;32m    223\u001b[0m     logme\u001b[39m.\u001b[39mexception(\u001b[39m__name__\u001b[39m\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m:Lookup:Unexpected exception occured while attempting to get or create a new event loop.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    224\u001b[0m     \u001b[39mraise\u001b[39;00m\n\u001b[1;32m--> 226\u001b[0m get_event_loop()\u001b[39m.\u001b[39;49mrun_until_complete(Twint(config)\u001b[39m.\u001b[39;49mmain(callback))\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py:618\u001b[0m, in \u001b[0;36mBaseEventLoop.run_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Run until the Future is done.\u001b[39;00m\n\u001b[0;32m    608\u001b[0m \n\u001b[0;32m    609\u001b[0m \u001b[39mIf the argument is a coroutine, it is wrapped in a Task.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[39mReturn the Future's result, or raise its exception.\u001b[39;00m\n\u001b[0;32m    616\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    617\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m--> 618\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_running()\n\u001b[0;32m    620\u001b[0m new_task \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m futures\u001b[39m.\u001b[39misfuture(future)\n\u001b[0;32m    621\u001b[0m future \u001b[39m=\u001b[39m tasks\u001b[39m.\u001b[39mensure_future(future, loop\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py:578\u001b[0m, in \u001b[0;36mBaseEventLoop._check_running\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_running\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    577\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_running():\n\u001b[1;32m--> 578\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mThis event loop is already running\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    579\u001b[0m     \u001b[39mif\u001b[39;00m events\u001b[39m.\u001b[39m_get_running_loop() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    580\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    581\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mCannot run the event loop while another loop is running\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: This event loop is already running"
     ]
    }
   ],
   "source": [
    "followings = {}\n",
    "following_list = []\n",
    "for person in users:\n",
    "    print('#####\\nStarting: ' + person + '\\n#####')\n",
    "    try:\n",
    "        followings[person] = get_followings(person)\n",
    "        following_list = following_list + followings[person]\n",
    "    except KeyError:\n",
    "        print('IndexError')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(following_list).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "follow_relations ={}\n",
    "for following_user in followings.keys():\n",
    "    follow_relation_list = []\n",
    "    for followed_user in followings.keys():\n",
    "        if followed_user in followings[following_user]:\n",
    "            follow_relation_list.append(True)\n",
    "        else:\n",
    "            follow_relation_list.append(False)\n",
    "    follow_relations[following_user] = follow_relation_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "following_df = pd.DataFrame.from_dict(follow_relations, \n",
    "                                      orient='index', columns=followings.keys())\n",
    "following_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping to Create a CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python39\\lib\\ast.py:50: RuntimeWarning: coroutine 'Twint.main' was never awaited\n",
      "  return compile(source, filename, mode, flags,\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 500: Internal Server Error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\andre\\OneDrive\\Documenti\\tuttooo\\Python\\Web Scraping.ipynb Cell 19\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andre/OneDrive/Documenti/tuttooo/Python/Web%20Scraping.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39murllib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrequest\u001b[39;00m \u001b[39mimport\u001b[39;00m urlopen \u001b[39mas\u001b[39;00m uReq\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andre/OneDrive/Documenti/tuttooo/Python/Web%20Scraping.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m my_url\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://www.flipkart.com/search?q=samsung+mobiles&amp;sid=tyy\u001b[39m\u001b[39m%\u001b[39m\u001b[39m2C4io&amp;as=on&amp;as-show=on&amp;otracker=AS_QueryStore_HistoryAutoSuggest_0_2&amp;otracker1=AS_QueryStore_HistoryAutoSuggest_0_2&amp;as-pos=0&amp;as-type=HISTORY&amp;as-searchtext=sa\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/andre/OneDrive/Documenti/tuttooo/Python/Web%20Scraping.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m uClient \u001b[39m=\u001b[39m uReq(my_url)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andre/OneDrive/Documenti/tuttooo/Python/Web%20Scraping.ipynb#X25sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m page_html \u001b[39m=\u001b[39m uClient\u001b[39m.\u001b[39mread()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andre/OneDrive/Documenti/tuttooo/Python/Web%20Scraping.ipynb#X25sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m uClient\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python39\\lib\\urllib\\request.py:214\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     opener \u001b[39m=\u001b[39m _opener\n\u001b[1;32m--> 214\u001b[0m \u001b[39mreturn\u001b[39;00m opener\u001b[39m.\u001b[39;49mopen(url, data, timeout)\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python39\\lib\\urllib\\request.py:523\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[39mfor\u001b[39;00m processor \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_response\u001b[39m.\u001b[39mget(protocol, []):\n\u001b[0;32m    522\u001b[0m     meth \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 523\u001b[0m     response \u001b[39m=\u001b[39m meth(req, response)\n\u001b[0;32m    525\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python39\\lib\\urllib\\request.py:632\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    629\u001b[0m \u001b[39m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    630\u001b[0m \u001b[39m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m code \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m):\n\u001b[1;32m--> 632\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparent\u001b[39m.\u001b[39;49merror(\n\u001b[0;32m    633\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mhttp\u001b[39;49m\u001b[39m'\u001b[39;49m, request, response, code, msg, hdrs)\n\u001b[0;32m    635\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python39\\lib\\urllib\\request.py:561\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m http_err:\n\u001b[0;32m    560\u001b[0m     args \u001b[39m=\u001b[39m (\u001b[39mdict\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhttp_error_default\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m+\u001b[39m orig_args\n\u001b[1;32m--> 561\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_chain(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python39\\lib\\urllib\\request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m handlers:\n\u001b[0;32m    493\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 494\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    495\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    496\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python39\\lib\\urllib\\request.py:641\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhttp_error_default\u001b[39m(\u001b[39mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 641\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(req\u001b[39m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 500: Internal Server Error"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as soup\n",
    "from urllib.request import urlopen as uReq\n",
    "\n",
    "my_url=\"https://www.flipkart.com/search?q=samsung+mobiles&amp;sid=tyy%2C4io&amp;as=on&amp;as-show=on&amp;otracker=AS_QueryStore_HistoryAutoSuggest_0_2&amp;otracker1=AS_QueryStore_HistoryAutoSuggest_0_2&amp;as-pos=0&amp;as-type=HISTORY&amp;as-searchtext=sa\"\n",
    "\n",
    "uClient = uReq(my_url)\n",
    "page_html = uClient.read()\n",
    "uClient.close()\n",
    "page_soup = soup(page_html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'page_soup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\andre\\OneDrive\\Documenti\\tuttooo\\Python\\Web Scraping.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/andre/OneDrive/Documenti/tuttooo/Python/Web%20Scraping.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m containers \u001b[39m=\u001b[39m page_soup\u001b[39m.\u001b[39mfindAll(\u001b[39m\"\u001b[39m\u001b[39mdiv\u001b[39m\u001b[39m\"\u001b[39m, { \u001b[39m\"\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m_3O0U0u\u001b[39m\u001b[39m\"\u001b[39m})\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andre/OneDrive/Documenti/tuttooo/Python/Web%20Scraping.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(containers))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'page_soup' is not defined"
     ]
    }
   ],
   "source": [
    "containers = page_soup.findAll(\"div\", { \"class\": \"_3O0U0u\"})\n",
    "print(len(containers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'containers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\andre\\OneDrive\\Documenti\\tuttooo\\Python\\Web Scraping.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/andre/OneDrive/Documenti/tuttooo/Python/Web%20Scraping.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(soup\u001b[39m.\u001b[39mprettify(containers[\u001b[39m0\u001b[39m]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'containers' is not defined"
     ]
    }
   ],
   "source": [
    "print(soup.prettify(containers[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'containers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\andre\\OneDrive\\Documenti\\tuttooo\\Python\\Web Scraping.ipynb Cell 22\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/andre/OneDrive/Documenti/tuttooo/Python/Web%20Scraping.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m container \u001b[39m=\u001b[39m containers[\u001b[39m0\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andre/OneDrive/Documenti/tuttooo/Python/Web%20Scraping.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(container\u001b[39m.\u001b[39mdiv\u001b[39m.\u001b[39mimg[\u001b[39m\"\u001b[39m\u001b[39malt\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'containers' is not defined"
     ]
    }
   ],
   "source": [
    "container = containers[0]\n",
    "print(container.div.img[\"alt\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
